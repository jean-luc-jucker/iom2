`21_socialize_dim_score` = `21_socialize_n` * `21_socialize_dim_weight`,
`21_socialize_comp_score` = `21_socialize_n` * `21_socialize_comp_weight`,
`22_network_dim_score` = `22_network_n` * `22_network_dim_weight`,
`22_network_comp_score` = `22_network_n` * `22_network_comp_weight`,
`23_community_dim_score` = `23_community_n` * `23_community_dim_weight`,
`23_community_comp_score` = `23_community_n` * `23_community_comp_weight`,
`24_safety_dim_score` = `24_safety_n` * `24_safety_dim_weight`,
`24_safety_comp_score` = `24_safety_n` * `24_safety_comp_weight`,
`25_family_conflict_dim_score` = `25_family_conflict_n` * `25_family_conflict_dim_weight`,
`25_family_conflict_comp_score` = `25_family_conflict_n` * `25_family_conflict_comp_weight`,
`26_discrimination_dim_score` = `26_discrimination_n` * `26_discrimination_dim_weight`,
`26_discrimination_comp_score` = `26_discrimination_n` * `26_discrimination_comp_weight`,
`27_distress_dim_score` = `27_distress_n` * `27_distress_dim_weight`,
`27_distress_comp_score` = `27_distress_n` * `27_distress_comp_weight`,
`28_psy_support_dim_score` = `28_psy_support_n` * `28_psy_support_dim_weight`,
`28_psy_support_comp_score` = `28_psy_support_n` * `28_psy_support_comp_weight`,
`29_30_remigration_construct_dim_score` = `29_30_remigration_construct` * `29_30_remigration_construct_dim_weight`, # construct!
`29_30_remigration_construct_comp_score` = `29_30_remigration_construct` * `29_30_remigration_construct_comp_weight`, # construct!
) %>%
# COMPUTE DIMENSIONAL SCORES ################################################
# Economic (9 indicators)
mutate(EconomicScore =
`1_economic_dim_score` + `2_food_dim_score` + `3_borrow_dim_score` + `4_borrow_freq_dim_score` + `5_debt_ratio_dim_score` + `6_employment_dim_score` + `7_working_dim_score` + `8_assets_dim_score` + `9_searching_job_dim_score`,
# Social (11 indicators)
SocialScore = `10_housing_dim_score` + `11_housing_qual_dim_score` + `12_education_dim_score` + `13_school_dim_score` + `14_justice_dim_score` + `15_id_dim_score` + `16_documentation_dim_score` + `17_water_dim_score` + `18_health_dim_score` + `19_health_qual_dim_score` + `20_services_construct_dim_score`,
# Psycho social (9 indicators)
PsychoSocialScore = `21_socialize_dim_score` + `22_network_dim_score` + `23_community_dim_score` + `24_safety_dim_score` + `25_family_conflict_dim_score` + `26_discrimination_dim_score` + `27_distress_dim_score` + `28_psy_support_dim_score` + `29_30_remigration_construct_dim_score`
) %>%
# COMPUTE COMPOSITE SCORE ################################################
# 29 indicators
mutate(CompositeScore = `1_economic_comp_score` + `2_food_comp_score` + `3_borrow_comp_score` + `4_borrow_freq_comp_score` + `5_debt_ratio_comp_score` + `6_employment_comp_score` + `7_working_comp_score` + `8_assets_comp_score` + `9_searching_job_comp_score` + `10_housing_comp_score` + `11_housing_qual_comp_score` + `12_education_comp_score` + `13_school_comp_score` + `14_justice_comp_score` + `15_id_comp_score` + `16_documentation_comp_score` + `17_water_comp_score` + `18_health_comp_score` + `19_health_qual_comp_score` + `20_services_construct_comp_score` + `21_socialize_comp_score` + `22_network_comp_score` + `23_community_comp_score` + `24_safety_comp_score` + `25_family_conflict_comp_score` + `26_discrimination_comp_score` + `27_distress_comp_score` + `28_psy_support_comp_score` + `29_30_remigration_construct_comp_score`
)
# Warnings
# (1) Problem while computing `8_assets_n = recode(...)`. Can be safely ignored,
# since NA are replaced following it, on purpose.
# Before the merge, interview_data from Kobo needs to be converted to proper date
# Type before
typeof(kobo_slim$interview_date) # char
# NA before
sum(is.na(kobo_slim$interview_date)) # 0
# Print a few dates
kobo_slim$interview_date # seems to be in y-m-d format
# Let's try to convert
library(lubridate)
kobo_slim$interview_date <-  ymd(kobo_slim$interview_date)
# Type after
typeof(kobo_slim$interview_date) # double
# NA after
sum(is.na(kobo_slim$interview_date)) # 0, all good
# Also check using str
str(kobo_slim) # Now a date
# 3. MERGE ####
# Objects dimensions
dim(mimosa_slim) # 2,580 x  30
dim(kobo_slim)   # 1,385 x 187
# Target dimension
# 1,385 x 216
# Check duplicates in Mimosa (not an issue, just for the record)
sum(duplicated(mimosa$`CaseNo/IndividualNo`)) # 13
sum(duplicated(mimosa_slim$ID))  # 13
mimosa_slim[duplicated(mimosa_slim$ID), 'ID']
# We'll do a right join, keeping all rows from kobo_slim
rss <- merge(mimosa_slim, kobo_slim, by='ID', all.y = TRUE)
# Dimensions
dim(rss) # 1,385 x 216 --> as expected
# Check perfect duplicates
sum(duplicated(rss)) # 0
# Check pseudo-duplicates
sum(duplicated(rss$ID)) # 128
# Note all these duplicates are NA, as expected
rss[duplicated(rss$ID), "ID"]
# Compute last needed variable
rss  <- rss %>% mutate(MBAssistanceDuration =
as.numeric(difftime(interview_date, MicrobusinessEndDate, units = "days")))
# Final dimensions
dim(rss) # 1,385 x 217 --> as expected
# EXPORT FULL DATA ####
#write_excel_csv(rss, 'data_clean/rss.csv')
# RDS version
#saveRDS(rss, file = 'data_clean/rss.rds')
# SUBSET A SLIM VERSION ####
# Useful to have a slim version before doing any cleaning and recoding
rss_slim <- rss %>%
# SELECT
select(ID,
# Dependent variables
EconomicScore,
SocialScore,
PsychoSocialScore,
CompositeScore,
# Independent variables
# (a) Numeric
migration_duration,
TrainingDuration,
MBSupportDuration,
MBAssistanceDuration,
MBTimeToReceiveAssistance,
# (b) Categorical
sex,
age, # --> to convert to num in due time
return_country,
origin_country,
VOTs,
UMINOR,
HealthCondition,
# (c) Assistance
CounsellingStatus,
EconomicSupport,
FinancialServices,
JobPlacement,
Microbusiness,
Training,
SocialSupport,
ChildCare,
Education,
Housing,
LegalServices,
MaterialAssistance,
MedicalSupport,
SocialProtectionSchemes,
PsychosocialSupport,
# (d) Other
Microbusinesslevel,
MicrobusinessDeliveredBy,
MicrobusinessFormOfAssistance
)
dim(rss_slim) # 1,385 x 35
# EXPORT SLIM DATA ####
#write_excel_csv(rss_slim, 'data_clean/rss_slim.csv')
# RDS version
#saveRDS(rss_slim, file = 'data_clean/rss_slim.rds')
# Recode Independent variables
colSums(is.na(rss_slim))
# Main assessment
# Before (print any variable needed)
#rss_slim %>% group_by(Microbusiness) %>% summarise(count = n()) %>%
#  mutate(percent = count/sum(count)*100) %>% arrange(-percent) %>% print(n=21)
# Decision taken are as below. Main principles:
# (1) Variables with only 2 levels and one of them being small (less than 100)
# are dropped
# (2) Variables that have many levels and can be recoded are recoded
# (3) Variables with 2 levels and smallest level being of acceptable size
# are kept, but NA are recoded to unknown, to avoid losing 189 obs in most cases
# Variable-------------------------Levels ---Smallest -----NA -----Decision
# sex: -------------------------------- 2 ------  195 ----- 0 ---> keep as is
# return_country: -------------------- 20 --------- 1 ----- 0 ---> recode
# origin_country: -------------------- 12 -------- 43 ----- 0 ---> recode
# VOTs: ------------------------------- 2 -------- 27 --- 189 ---> drop variable
# UMINOR: ----------------------------- 2 --------- 6 --- 189 ---> drop variable
# HealthCondition:--------------------- 2 -------- 59 --- 189 ---> drop variable
# CounsellingStatus:------------------- 5 ------- *70 --- 325 ---> drop variable
# EconomicSupport:--------------------- 2 --------- 4 --- 189 ---> drop variable
# FinancialServices:------------------- 2 ------- 345 --- 189 ---> keep variable, fill NA (189)
# JobPlacement:------------------------ 2 --------- 2 --- 189 ---> drop variable
# Microbusiness:----------------------- 2 -------- 12 --- 189 ---> drop variable
# Training:---------------------------- 2 ------- 581 --- 189 ---> keep variable, fill NA (189)
# SocialSupport:----------------------- 2 ------- 198 --- 189 ---> keep variable, fill NA (189)
# ChildCare:--------------------------- 2 --------- 2 --- 189 ---> drop variable
# Education:--------------------------- 2 --------- 4 --- 189 ---> drop variable
# Housing:----------------------------- 2 -------- 19 --- 189 ---> drop variable
# LegalServices:----------------------- 2 -------- 39 --- 189 ---> drop variable
# MaterialAssistance :----------------- 2 ------- 154 --- 189 ---> keep variable, fill NA (189)
# MedicalSupport:---------------------- 2 ------- 193 --- 189 ---> keep variable, fill NA (189)
# SocialProtectionSchemes:------------- 2 --------- 1 --- 189 ---> drop variable
# PsychosocialSupport:----------------- 2 ------- 434 --- 189 ---> keep variable, fill NA (189)
# Microbusinesslevel:------------------ 3 ------- *33 --- 201 ---> drop variable
# MicrobusinessDeliveredBy:------------ 2 -------- 23 --- 201 ---> drop variable
# MicrobusinessFormOfAssistance:------- 3 ------- 186 --- 262 ---> keep variable, fill NA (262)
# Note, levels do NOT include NA level
# *several categories, but cannot be combined
# Let's implement the above
# Size before
dim(rss_slim) # 1385 x 35
rss_slim <- rss_slim %>% mutate(
# RECODE
return_country =
case_when(
return_country != "Libye" & return_country != "Niger" & return_country != "AlgÃ©rie"  ~ 'Autre',
TRUE ~ as.character(return_country)
),
origin_country =
case_when(
origin_country != "Niger" & origin_country != "Guinee Conakry" & origin_country != "Mali" & origin_country != "Tchad"  ~ 'Autre',
TRUE ~ as.character(origin_country)
)
) %>%
# FILL NA
mutate(MicrobusinessFormOfAssistance = replace_na(MicrobusinessFormOfAssistance, 'Unknown'),
FinancialServices = replace_na(FinancialServices, 'Unknown'),
Training = replace_na(Training, 'Unknown'),
SocialSupport = replace_na(SocialSupport, 'Unknown'),
MaterialAssistance = replace_na(MaterialAssistance, 'Unknown'),
MedicalSupport = replace_na(MedicalSupport, 'Unknown'),
PsychosocialSupport = replace_na(PsychosocialSupport, 'Unknown'),
) %>%
# DROP VARIABLES
select(-c(VOTs, UMINOR, HealthCondition, CounsellingStatus, EconomicSupport,
JobPlacement, Microbusiness, ChildCare, Education, Housing,
LegalServices, SocialProtectionSchemes, Microbusinesslevel,
MicrobusinessDeliveredBy)
)
# After (print any)
#rss_slim %>% group_by(FinancialServices) %>% summarise(count = n()) %>%
#  mutate(percent = count/sum(count)*100) %>% arrange(-percent)
dim(rss_slim) # 1,385 x 21 (14 columns less, as expected)
# Outliers; fill NA in numeric variables
# Variables to process
# Age (years)
# Not computed
# To be converted to num first
# Conversion might coerce to NA; check NA count before
sum(is.na(rss_slim$age)) # 0
# Print levels before
rss_slim %>% group_by(age) %>% summarise(count = n()) %>% print(n=58)
# Convert to number
rss_slim$age  <- as.numeric(rss_slim$age)
# Print levels after
rss_slim %>% group_by(age) %>% summarise(count = n()) %>% print(n=58) # all good
# Check NA count after
sum(is.na(rss_slim$age)) # 0, all good
# Summarise
summary(rss_slim$age) # median = 28, min = 0, max = 300
# First we'll convert some values that are obvious mistakes to NA
rss_slim[rss_slim$age < 14 | rss_slim$age > 100, 'age']  <- NA
length(rss_slim[rss_slim$age < 14 | rss_slim$age > 100, 'age']) # 19
# We should now have 19 NA
sum(is.na(rss_slim$age)) # 19 as expected
# Let's re-summarise
summary(rss_slim$age)
# And let's store the median
q_median <- median(rss_slim$age, na.rm = TRUE)
q_median # 28 years old
# Although age has outliers, it seems reasonably distributed
# We'll therefore do not replace outliers, but simply replace all NA
# with the median
rss_slim[is.na(rss_slim$age), 'age']  <- q_median
# Let's re-summarise
summary(rss_slim$age) # median still 28
# We should now have 0 NA
sum(is.na(rss_slim$age)) # 0 as expected
# migration_duration (years)
# Not computed
# Warning, I wonder if some answers are not weeks instead of years!!!
# To be converted to num first
# Conversion might coerce to NA; check NA count before
sum(is.na(rss_slim$migration_duration)) # 0
# Print levels before
rss_slim %>% group_by(migration_duration) %>% summarise(count = n()) %>% print(n=49)
# Convert to number
rss_slim$migration_duration  <- as.numeric(rss_slim$migration_duration)
# Print levels after
rss_slim %>% group_by(migration_duration) %>% summarise(count = n()) %>% print(n=49) # all good
# Check NA count after
sum(is.na(rss_slim$migration_duration)) # 0, all good
# First, we'll replace these 7 values, which are mistakes and not outliers,
# with NA
sort(rss_slim[rss_slim$migration_duration > 100, "migration_duration"])
rss_slim[rss_slim$migration_duration > 100, "migration_duration"]  <- NA
# Summarise
summary(rss_slim$migration_duration) # median = 2, min 0, max 86, NA 7, all as expected
# Let's store the median
q_median <- median(rss_slim$migration_duration, na.rm = TRUE)
q_median # 2 years
# Spot outliers using percentile method, with conservative threshold of 0.01/0.99
lower_bound <- quantile(rss_slim$migration_duration, 0.01, na.rm = TRUE)
upper_bound <- quantile(rss_slim$migration_duration, 0.99, na.rm = TRUE)
outlier_ind <- which(rss_slim$migration_duration < lower_bound | rss_slim$migration_duration > upper_bound)
length(rss_slim[outlier_ind, "migration_duration"]) # 12 outliers,
sort(rss_slim[outlier_ind, "migration_duration"]) # with smallest being 60 years
# Replace 18 extreme outliers with median
rss_slim[outlier_ind, "migration_duration"] <- q_median
# Re-summarise
summary(rss_slim$migration_duration) # median still 2, max 48 years as expected
# We should still have the same number of NA
sum(is.na(rss_slim$migration_duration)) # 7 --> as expected
# And we will also replace them with the median
rss_slim[is.na(rss_slim$migration_duration), "migration_duration"] <- q_median
# Re-summarise
summary(rss_slim$migration_duration) # median still 2, max still 48
# No NA should remain
sum(is.na(rss_slim$migration_duration)) # 0, all good
# TrainingDuration (days)
# Computed from Mimosa:
# TrainingEndDate - TrainingStartDate
# Summarise
summary(rss_slim$TrainingDuration) # median = 4, min 0, max 167, NA 770
# NA
sum(is.na(rss_slim$TrainingDuration)) # 770
# We have 770 NA. Logically, all these NA should be people who did not receive
# training or that we recoded as Unknown above. Let's check
rss_slim %>% group_by(Training) %>% summarise(count = n())
# No         581
# Unknown    189
# Yes        615
# That is the case, however, we cannot be sure that the Unknown received no training!
# But we decide to recode all these 770 cases as 0 days of training, which will need
# to be reported (i.e., 189 Unknown were recoded to 0 days).
# Another thing we need to check is that no people who receive training are NA or have
# 0 days of training. Let's check:
dim(rss_slim[rss_slim$Training == 'Yes' & rss_slim$TrainingDuration == 0 & !is.na(rss_slim$TrainingDuration), c('Training', 'TrainingDuration')]) # 115
# Unfortunatly, we have 115 respondents who stated they received training, but have 0
# days of training.
# So what we'll do is this. We will add one day to all respondents, and code the NA as
# 0, like this, we'll still be able to differentiate between No training and training.
# This too will need to be reported.
rss_slim$TrainingDuration <- rss_slim$TrainingDuration + 1
# Re-summarise
summary(rss_slim$TrainingDuration) # median = 4, min now 1, max now 168, NA still 770,
# all as expected
# We will now check for outliers. We will replace NA with 0 after this, because doing it
# now would change the median to 0, which would be incorrect for those outliers who did
# received training.
# Also, we will use the median before adding the ones, since this seems more adequate.
# Let's store the median
q_median <- 4 # exception, from above
# Spot outliers using percentile method, with conservative threshold of 0.01/0.99
lower_bound <- quantile(rss_slim$TrainingDuration, 0.01, na.rm = TRUE)
upper_bound <- quantile(rss_slim$TrainingDuration, 0.99, na.rm = TRUE)
outlier_ind <- which(rss_slim$TrainingDuration < lower_bound | rss_slim$TrainingDuration > upper_bound)
length(rss_slim[outlier_ind, "TrainingDuration"]) # 7 outliers,
sort(rss_slim[outlier_ind, "TrainingDuration"]) # with smallest being 83 days
# Replace 7 extreme outliers with first median
rss_slim[outlier_ind, "TrainingDuration"] <- q_median
# Re-summarise
summary(rss_slim$TrainingDuration) # median = 5, min still 1, max 74 as expected, NA still 770,
# all as expected
# Note median is now 5 (not 4), because of the added ones. That said, we replaced the values of
# outliers with the original median, 4
# Let us now finally code all the NA as 0 days:
rss_slim <- rss_slim %>% mutate(TrainingDuration = replace_na(TrainingDuration, 0))
# Re-check NA
sum(is.na(rss_slim$TrainingDuration)) # 0 as expected
# Re-summarise
summary(rss_slim$TrainingDuration) # median is now 0 (as expected), min is 0 (as expected),
# and max is still 74
# Let's plot our final distribution
boxplot(rss_slim$TrainingDuration,
ylab = "Days",
main = "TrainingDuration"
)
# Skewed to 0, but better than losing all these observations, I guess, and difficult to
# do better given inconsistency in the data mentioned above.
# MBSupportDuration (days)
# Computed from Mimosa:
# MicrobusinessEndDate - ArrivalDate
# Summarise
summary(rss_slim$MBSupportDuration) # median = 121.5, min -191 (!), max 1658, NA 203
# NA
sum(is.na(rss_slim$MBSupportDuration)) # 203
# First, investigate negative numbers
rss_slim[rss_slim$MBSupportDuration <= 0 & !is.na(rss_slim$MBSupportDuration), "MBSupportDuration"]
# There is only one, which we will convert to NA
rss_slim[rss_slim$MBSupportDuration <= 0 & !is.na(rss_slim$MBSupportDuration), "MBSupportDuration"]  <- NA
# Re-summarise
summary(rss_slim$MBSupportDuration) # median now 122, min now 2, max still 1658, NA now 204, all
# as expected
# As for TrainingDuration, we will replace the NA with 0. That said, we do not have the same
# issue concerning respondents who received training with 0 days.
# Again, we'll do the change after spotting outliers.
# Let's store the median
q_median <- 121.5 # exception, from above
# Spot outliers using percentile method, with conservative threshold of 0.01/0.99
lower_bound <- quantile(rss_slim$MBSupportDuration, 0.01, na.rm = TRUE)
upper_bound <- quantile(rss_slim$MBSupportDuration, 0.99, na.rm = TRUE)
outlier_ind <- which(rss_slim$MBSupportDuration < lower_bound | rss_slim$MBSupportDuration > upper_bound)
length(rss_slim[outlier_ind, "MBSupportDuration"]) # 12 outliers,
sort(rss_slim[outlier_ind, "MBSupportDuration"]) # with smallest being 384 days
# Replace 12 extreme outliers with first median
rss_slim[outlier_ind, "MBSupportDuration"] <- q_median
# Re-summarise
summary(rss_slim$MBSupportDuration) # median still 121.5, min still 2, max now 383, NA still 204,
# all as expected
# Let us now finally code all the NA as 0 days:
rss_slim <- rss_slim %>% mutate(MBSupportDuration = replace_na(MBSupportDuration, 0))
# Re-check NA
sum(is.na(rss_slim$MBSupportDuration)) # 0 as expected
# Re-summarise
summary(rss_slim$MBSupportDuration) # median is now 96, min is now 0,
# and max is still 383
# Let's plot our final distribution
boxplot(rss_slim$MBSupportDuration,
ylab = "Days",
main = "MBSupportDuration"
)
# Looking quite good.
# NEW MBTimeToReceiveAssistance (days)
# Computed from Mimosa:
# CounsellingEndDate - ArrivalDate
# Summarise
summary(rss_slim$MBTimeToReceiveAssistance) # median = 1, min -763 (!), max 1354, NA 395
# NA
sum(is.na(rss_slim$MBTimeToReceiveAssistance)) # 395
# First, investigate negative numbers
rss_slim[rss_slim$MBTimeToReceiveAssistance < 0 & !is.na(rss_slim$MBTimeToReceiveAssistance), "MBTimeToReceiveAssistance"]
# There are 300+ of them (report to Julie), which we will convert to NA
# Note, we keep the 0 as they are
rss_slim[rss_slim$MBTimeToReceiveAssistance < 0 & !is.na(rss_slim$MBTimeToReceiveAssistance), "MBTimeToReceiveAssistance"]  <- NA
# Re-summarise
summary(rss_slim$MBTimeToReceiveAssistance) # median now 7, min now 0, max still 1364, NA now 690, all
# as expected
# Let us store the current median. We'll replace NA after spotting outliers
# Let's store the median
q_median <- 7 # exception
# Spot outliers using percentile method, with conservative threshold of 0.01/0.99
lower_bound <- quantile(rss_slim$MBTimeToReceiveAssistance, 0.01, na.rm = TRUE)
upper_bound <- quantile(rss_slim$MBTimeToReceiveAssistance, 0.99, na.rm = TRUE)
outlier_ind <- which(rss_slim$MBTimeToReceiveAssistance < lower_bound | rss_slim$MBTimeToReceiveAssistance > upper_bound)
length(rss_slim[outlier_ind, "MBTimeToReceiveAssistance"]) # 7 outliers,
sort(rss_slim[outlier_ind, "MBTimeToReceiveAssistance"]) # with smallest being 198 days
# Replace 7 extreme outliers with first median
rss_slim[outlier_ind, "MBTimeToReceiveAssistance"] <- q_median
# Re-summarise
summary(rss_slim$MBTimeToReceiveAssistance) # median still 7, min still 0, max now 195, NA still 690,
# all as expected
# Let us replace the NA with the median
rss_slim <- rss_slim %>% mutate(MBTimeToReceiveAssistance = replace_na(MBTimeToReceiveAssistance, q_median))
# Re-check NA
sum(is.na(rss_slim$MBTimeToReceiveAssistance)) # 0 as expected
# Re-summarise
summary(rss_slim$MBTimeToReceiveAssistance) # median still 7, min still 0,
# max still 195
# Let's plot our final distribution
boxplot(rss_slim$MBTimeToReceiveAssistance,
ylab = "Days",
main = "MBTimeToReceiveAssistance"
)
# Not looking much better, but it's hard to improve.
# MBAssistanceDuration (days)
# Computed from Mimosa and Kobo
# interview_date [Kobo] - MicrobusinessEndDate [Mimosa]
# Summarise
summary(rss_slim$MBAssistanceDuration) # median = 169, min -146 (!), max 1951, NA 201
# NA
sum(is.na(rss_slim$MBAssistanceDuration)) # 201
# These 201 NA corresponds to the count of people who received Microbusiness assistance,
# from above:
#Microbusiness
# Yes            1184
# NA              189
# No               12
# 189 + 12 = 201
# We cannot be sure that the NA received no assistance, that said, similarly to what we done
# for TrainingDuration, we'll recode them as 0 after spotting outliers.
# We also need to investigate the negative numbers
rss_slim[rss_slim$MBAssistanceDuration <= 0 & !is.na(rss_slim$MBAssistanceDuration), "MBAssistanceDuration"]
length(rss_slim[rss_slim$MBAssistanceDuration <= 0 & !is.na(rss_slim$MBAssistanceDuration), "MBAssistanceDuration"]) # 52
# Also print levels, since there seems to be zeros
#rss_slim %>% group_by(MBAssistanceDuration) %>% summarise(count = n()) %>% print(n=351) # there
# are 2 zeros, which we will ignore; run only if needed
# There are 52 of them. That said, these should not be converted to NA, since we know the
# NA are already all accounted above. We'll replace them with the median after computing the
# median without taking account of them
# The first thing we need to do is compute the median without taking into account the zeros
length(rss_slim[rss_slim$MBAssistanceDuration > 0, "MBAssistanceDuration"]) # 1333, which is
# 1385 - 52 indeed
# Store median
q_median <- median(rss_slim[rss_slim$MBAssistanceDuration > 0, "MBAssistanceDuration"], na.rm = TRUE)
q_median
# 174.5, which is slightly higher than above (since we do not take into account zeros), indeed
# Replace 52 negative numbers with the median
rss_slim[rss_slim$MBAssistanceDuration <= 0 & !is.na(rss_slim$MBAssistanceDuration), "MBAssistanceDuration"] <- q_median
# Check no negative values remain
length(rss_slim[rss_slim$MBAssistanceDuration <= 0 & !is.na(rss_slim$MBAssistanceDuration), "MBAssistanceDuration"]) # 0 indeed
# Check NA is still 201
sum(is.na(rss_slim$MBAssistanceDuration)) # 201 indeed
# Resummarize
summary(rss_slim$MBAssistanceDuration) # median now 174.5, min now 1, max still 1951, all as expected
# Spot outliers using percentile method, with conservative threshold of 0.01/0.99
lower_bound <- quantile(rss_slim$MBAssistanceDuration, 0.01, na.rm = TRUE)
upper_bound <- quantile(rss_slim$MBAssistanceDuration, 0.99, na.rm = TRUE)
outlier_ind <- which(rss_slim$MBAssistanceDuration < lower_bound | rss_slim$MBAssistanceDuration > upper_bound)
length(rss_slim[outlier_ind, "MBAssistanceDuration"]) # 21 outliers,
sort(rss_slim[outlier_ind, "MBAssistanceDuration"]) # with smallest being 1 days or 381 days
# We don't want to get rid of lower bound outliers, but only upper bound outliers.
# So we do:
outlier_ind <- which(rss_slim$MBAssistanceDuration > upper_bound) # only take upper bound
length(rss_slim[outlier_ind, "MBAssistanceDuration"]) # 10 outliers (as expected),
sort(rss_slim[outlier_ind, "MBAssistanceDuration"]) # with smallest still 381 days
# Replace 10 extreme outliers with first median
rss_slim[outlier_ind, "MBAssistanceDuration"] <- q_median
# Re-summarise
summary(rss_slim$MBAssistanceDuration) # median still 174.5, min still 1, max now 377, NA still 201,
# all as expected
# Let us now finally code all the NA as 0 days:
rss_slim <- rss_slim %>% mutate(MBAssistanceDuration = replace_na(MBAssistanceDuration, 0))
# Re-check NA
sum(is.na(rss_slim$MBAssistanceDuration)) # 0 as expected
# Re-summarise
summary(rss_slim$MBAssistanceDuration) # median is now 158, min is now 0,
# and max is still 377, all as expected
# Let's plot our final distribution
boxplot(rss_slim$MBAssistanceDuration,
ylab = "Days",
main = "MBAssistanceDuration"
)
# Looking very good.
# Data types check
str(rss_slim) # all good
# Final NA check
colSums(is.na(rss_slim)) # all good
# Export slim recoded data
write_excel_csv(rss_slim, 'data_clean/rss_slim_recoded.csv')
# RDS version
saveRDS(rss_slim, file = 'data_clean/rss_slim_recoded.rds')
# Final size
dim(rss_slim)
# Export slim recoded data
write_excel_csv(rss_slim, 'data_clean/rss_slim_recoded.csv')
# Export slim recoded data
write_excel_csv(rss_slim, 'data_clean/rss_slim_recoded.csv')
# RDS version
saveRDS(rss_slim, file = 'data_clean/rss_slim_recoded.rds')
